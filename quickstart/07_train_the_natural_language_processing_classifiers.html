

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-138982267-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-138982267-1');
  </script>

  <title>Step 7: Train the Natural Language Processing Classifiers &mdash; The Conversational AI Playbook 4.3.1rc1 documentation</title>
  


  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'4.3.1rc1',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/custom.js"></script>
        <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@1/dist/clipboard.min.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Step 8: Configure the Language Parser" href="08_configure_the_language_parser.html" />
    <link rel="prev" title="Step 6: Generate Representative Training Data" href="06_generate_representative_training_data.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> The Conversational AI Playbook
          

          
          </a>

          
            
            
              <div class="version">
                4.3.1rc1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/introduction_to_conversational_applications.html">Introduction to Conversational Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/approaches_for_building_conversational_applications.html">Different Approaches for Building Conversational Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/anatomy_of_a_conversational_ai_interaction.html">Anatomy of a Conversational AI Interaction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/introducing_mindmeld.html">Introducing MindMeld</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/key_concepts.html">Key Concepts</a></li>
</ul>
<p class="caption"><span class="caption-text">Step-by-Step Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="00_overview.html">Building a Conversational Interface in 10 Steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="01_select_the_right_use_case.html">Step 1: Select the Right Use Case</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_script_interactions.html">Step 2: Script Your Ideal Dialogue Interactions</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_define_the_hierarchy.html">Step 3: Define the Domain, Intent, Entity, and Role Hierarchy</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_define_the_dialogue_handlers.html">Step 4: Define the Dialogue State Handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_create_the_knowledge_base.html">Step 5: Create the Knowledge Base</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_generate_representative_training_data.html">Step 6: Generate Representative Training Data</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Step 7: Train the Natural Language Processing Classifiers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#domain-classification">Domain Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#intent-classification">Intent Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#entity-recognition">Entity Recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="#role-classification">Role Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#entity-resolution">Entity Resolution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="08_configure_the_language_parser.html">Step 8: Configure the Language Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_optimize_question_answering_performance.html">Step 9: Optimize Question Answering Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_deploy_to_production.html">Step 10: Deploy Trained Models</a></li>
</ul>
<p class="caption"><span class="caption-text">Blueprint Applications</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../blueprints/overview.html">MindMeld Blueprints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blueprints/food_ordering.html">Food Ordering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blueprints/video_discovery.html">Video Discovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blueprints/home_assistant.html">Home Assistant</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blueprints/hr_assistant.html">HR Assistant</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blueprints/banking.html">Banking Assistant</a></li>
</ul>
<p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../userguide/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/architecture.html">Platform Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/preprocessor.html">Working with the Preprocessor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/nlp.html">Working with the Natural Language Processor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/domain_classifier.html">Working with the Domain Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/intent_classifier.html">Working with the Intent Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/entity_recognizer.html">Working with the Entity Recognizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/lstm.html">Using LSTM for Entity Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/role_classifier.html">Working with the Role Classifier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/entity_resolver.html">Working with the Entity Resolver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/parser.html">Working with the Language Parser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/custom_features.html">Working with User-Defined Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/kb.html">Working with the Knowledge Base and Question Answerer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/dm.html">Working with the Dialogue Manager</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/custom_action.html">Working with Custom Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/internationalization.html">Internationalization support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../userguide/voice.html">Dealing with Voice Inputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../integrations/webex_teams.html">Webex Teams Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../integrations/whatsapp.html">WhatsApp Integration</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../internal/api_reference.html">API Reference</a></li>
</ul>
<p class="caption"><span class="caption-text">MindMeld UI</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../mindmeld_ui/mindmeld_ui.html">MindMeld UI</a></li>
</ul>
<p class="caption"><span class="caption-text">Versions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../versions/changes.html">Recent Changes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versions/history.html">Package History</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">The Conversational AI Playbook</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Step 7: Train the Natural Language Processing Classifiers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/quickstart/07_train_the_natural_language_processing_classifiers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="step-7-train-the-natural-language-processing-classifiers">
<h1>Step 7: Train the Natural Language Processing Classifiers<a class="headerlink" href="#step-7-train-the-natural-language-processing-classifiers" title="Permalink to this headline">¶</a></h1>
<p>The Natural Language Processor (NLP) in MindMeld is tasked with understanding the user's natural language input. It analyzes the input using a hierarchy of classification models. Each model assists the next tier of models by narrowing the problem scope, or in other words successively narrowing down the 'solution space.'</p>
<p>As introduced in <a class="reference internal" href="03_define_the_hierarchy.html"><span class="doc">Step 3</span></a>, MindMeld applies four layers of classifiers in the following order:</p>
<ol class="arabic simple">
<li><strong>Domain Classifier</strong> classifies input into one of a pre-defined set of conversational domains. Only necessary for apps that handle conversations across varied topics, each with its own specialized vocabulary.</li>
<li><strong>Intent Classifiers</strong> determine what the user is trying to accomplish by assigning each input to one of the intents defined for your application.</li>
<li><strong>Entity Recognizers</strong> extract the words and phrases, or <em>entities</em>, that are required to fulfill the user's end goal.</li>
<li><strong>Role Classifiers</strong> assign a differentiating label, called a <em>role</em>, to the extracted entities. This level of categorization is only necessary where an entity of a particular type can have multiple meanings depending on the context.</li>
</ol>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The code examples in this chapter assume that you have installed the Kwik-E-Mart and Home
Assistant blueprint applications. See the
<a class="reference internal" href="../blueprints/overview.html"><span class="doc">blueprints overview page</span></a> for details on installing the apps.</p>
</div>
<p>To train the NLP classifiers for our Kwik-E-Mart store information app, we must first gather the necessary training data as described in <a class="reference internal" href="06_generate_representative_training_data.html"><span class="doc">Step 6</span></a>. Once the data is ready, we open a Python shell and start building the components of our natural language processor.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> <span class="nv">$MM_APP_ROOT</span>
python
</pre></div>
</div>
<p>In the Python shell, the quickest way to train all the NLP classifiers together is to use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">nlp.build()</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
</pre></div>
</div>
<p>This method trains all models in the specified NLP pipeline. The Natural Language Processor automatically infers which classifiers need to be trained based on the directory structure and the annotations in the training data. In our case, the NLP will train an intent classifier for the <code class="docutils literal notranslate"><span class="pre">store_info</span></code> domain and entity recognizers for each intent that contains labeled queries with entity annotations. Domain classification and role classification models will not be built because our simple example did not include training data for them.</p>
<p>To run all of the trained models in the NLP pipeline, use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">nlp.process()</span></code> command.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nlp</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="s1">&#39;When does Elm Street close?&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{&#39;text&#39;: &#39;When does Elm Street close?&#39;,</span>
<span class="go"> &#39;domain&#39;: &#39;store_info&#39;,</span>
<span class="go"> &#39;intent&#39;: &#39;get_store_hours&#39;,</span>
<span class="go"> &#39;entities&#39;: [{&#39;text&#39;: &#39;Elm Street&#39;,</span>
<span class="go">   &#39;type&#39;: &#39;store_name&#39;,</span>
<span class="go">   &#39;role&#39;: None,</span>
<span class="go">   &#39;value&#39;: [{&#39;cname&#39;: &#39;23 Elm Street&#39;,</span>
<span class="go">     &#39;score&#39;: 44.777046,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;Elm Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;1&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;104 First Street&#39;,</span>
<span class="go">     &#39;score&#39;: 7.0927515,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;104 First Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;5&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;East Oak Street&#39;,</span>
<span class="go">     &#39;score&#39;: 7.0927515,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;East Oak Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;12&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;257th Street&#39;,</span>
<span class="go">     &#39;score&#39;: 6.958622,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;257th Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;18&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;D Street&#39;,</span>
<span class="go">     &#39;score&#39;: 6.7008686,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;D Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;19&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;181st Street&#39;,</span>
<span class="go">     &#39;score&#39;: 6.630241,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;181st Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;17&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;West Oak Street&#39;,</span>
<span class="go">     &#39;score&#39;: 6.249679,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;West Oak Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;11&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;156th Street&#39;,</span>
<span class="go">     &#39;score&#39;: 6.1613703,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;156th Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;15&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;Peanut Street&#39;,</span>
<span class="go">     &#39;score&#39;: 6.1613703,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;Peanut Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;20&#39;},</span>
<span class="go">    {&#39;cname&#39;: &#39;Little Italy Store&#39;,</span>
<span class="go">     &#39;score&#39;: 5.2708626,</span>
<span class="go">     &#39;top_synonym&#39;: &#39;Third Street&#39;,</span>
<span class="go">     &#39;id&#39;: &#39;7&#39;}],</span>
<span class="go">   &#39;span&#39;: {&#39;start&#39;: 10, &#39;end&#39;: 19}}</span>
<span class="go">   ]</span>
<span class="go">}</span>
</pre></div>
</div>
<p>The <code class="xref py py-meth docutils literal notranslate"><span class="pre">nlp.process()</span></code> command returns detailed information about the output of each of the trained NLP models. See the <a class="reference internal" href="../userguide/nlp.html"><span class="doc">User Guide</span></a> for details.</p>
<p>By default, the <code class="xref py py-meth docutils literal notranslate"><span class="pre">build()</span></code> method shown above uses the baseline machine learning settings for all classifiers, which should train reasonable models in most cases. To further improve model performance, MindMeld provides extensive capabilities for optimizing individual model parameters and measuring results. We'll next explore how to experiment with different settings for each NLP component individually.</p>
<div class="section" id="domain-classification">
<span id="id1"></span><h2>Domain Classification<a class="headerlink" href="#domain-classification" title="Permalink to this headline">¶</a></h2>
<p>The domain classifier (also called the domain model) is a text classification model that is trained using the labeled queries across all domains. Our simple app only has one domain and hence does not need a domain classifier. However, complex conversational apps such as the popular virtual assistants on smartphones and smart speakers today have to handle queries from varied domains such as weather, navigation, sports, finance, and music, among others. Such apps use domain classification as the first step to narrow down the focus of the subsequent classifiers in the NLP pipeline.</p>
<p>To see the domain classifier in action, you can download and try out the <code class="docutils literal notranslate"><span class="pre">home_assistant</span></code> blueprint application.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mindmeld</span> <span class="k">as</span> <span class="nn">mm</span>
<span class="n">mm</span><span class="o">.</span><span class="n">configure_logs</span><span class="p">()</span>
<span class="n">mm</span><span class="o">.</span><span class="n">blueprint</span><span class="p">(</span><span class="s1">&#39;home_assistant&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">NaturalLanguageProcessor</span></code> class in MindMeld exposes methods for training, testing, and saving all the models in our classifier hierarchy, including the domain model. For example, suppose we want to build a <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression classifier</a> that does domain classification. In our Python shell, we start off by instantiating an object of the <code class="xref py py-class docutils literal notranslate"><span class="pre">NaturalLanguageProcessor</span></code> class. We then train the <code class="xref py py-attr docutils literal notranslate"><span class="pre">domain_classifier</span></code> model by calling its <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Since our simple Kwik-E-Mart app does not have a domain classifier, the example below uses the
<a class="reference internal" href="../blueprints/home_assistant.html"><span class="doc">Home Assistant</span></a> blueprint to demonstrate the functionality.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="s1">&#39;home_assistant&#39;</span><span class="p">)</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">domain_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model_settings</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;classifier_type&#39;</span><span class="p">:</span> <span class="s1">&#39;logreg&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>We test the trained classifier on a new query using the <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nlp</span><span class="o">.</span><span class="n">domain_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;close the kitchen door&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&#39;smart_home&#39;</span>
</pre></div>
</div>
<p>To view the classification probabilities associated with all available domains, we can use the <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_proba()</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nlp</span><span class="o">.</span><span class="n">domain_classifier</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="s1">&#39;close the kitchen door&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[</span>
<span class="go"> (&#39;smart_home&#39;, 0.9999634367987815),</span>
<span class="go"> (&#39;times_and_dates&#39;, 1.81768265134388e-05),</span>
<span class="go"> (&#39;weather&#39;, 1.2388247900671112e-05),</span>
<span class="go"> (&#39;unknown&#39;, 4.110616819853133e-06),</span>
<span class="go"> (&#39;greeting&#39;, 1.8875099844624723e-06)</span>
<span class="go">]</span>
</pre></div>
</div>
<p>In addition to the <cite>model</cite> parameter we used above, the <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method also takes parameters we can use to improve upon the baseline SVM model trained by default. These include parameters for features, cross-validation settings, and other model-specific configuration. See the <a class="reference internal" href="../userguide/domain_classifier.html"><span class="doc">User Guide</span></a> for details.</p>
</div>
<div class="section" id="intent-classification">
<span id="id2"></span><h2>Intent Classification<a class="headerlink" href="#intent-classification" title="Permalink to this headline">¶</a></h2>
<p>Intent classifiers (also called intent models) are text classification models that are trained, one-per-domain, using the labeled queries in each intent folder. Our Kwik-E-Mart app supports multiple intents (e.g. <code class="docutils literal notranslate"><span class="pre">greet</span></code>, <code class="docutils literal notranslate"><span class="pre">get_store_hours</span></code>, <code class="docutils literal notranslate"><span class="pre">find_nearest_store</span></code>, etc.) within the <code class="docutils literal notranslate"><span class="pre">store_info</span></code> domain. We will now see how to train an intent classifier that correctly maps user queries to one of these supported intents.</p>
<p>Training our intent model is similar to training the domain model using the <code class="xref py py-class docutils literal notranslate"><span class="pre">NaturalLanguageProcessor</span></code> class, but this time we explicitly define the features and cross-validation settings we want to use. For our intent classifier, let us assume that we want to build a <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> model and use <a class="reference external" href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag of words</a> and <a class="reference external" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-edgengram-tokenizer.html">edge n-grams</a> as features. Also, we would like to do <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation">k-fold cross validation</a>  with 10 splits to find the ideal <a class="reference external" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">hyperparameter</a> values.</p>
<p>We demonstrate intent classification using the simpler Kwik-E-Mart application. We start as before by instantiating a <code class="xref py py-class docutils literal notranslate"><span class="pre">NaturalLanguageProcessor</span></code> object.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> <span class="nv">$MM_APP_ROOT</span>
python
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, we define the feature dictionary that lists all the feature types along with the feature-specific settings. Let's say we want bag-of-n-grams up to size 2 and edge-ngrams up to length 2.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;bag-of-words&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;lengths&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="p">},</span>
    <span class="s1">&#39;edge-ngrams&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;lengths&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>We then define the hyperparameter selection settings.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">search_grid</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span>
  <span class="s1">&#39;class_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">hyperparam_settings</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;k-fold&#39;</span><span class="p">,</span>
  <span class="s1">&#39;k&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
  <span class="s1">&#39;grid&#39;</span><span class="p">:</span> <span class="n">search_grid</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Finally, we fetch the <code class="xref py py-attr docutils literal notranslate"><span class="pre">intent_classifier</span></code> for the domain we are interested in and call its <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method to train the model. The code below shows how to train an intent classifier for the <code class="docutils literal notranslate"><span class="pre">store_info</span></code> domain in our Kwik-E-Mart app.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">domains</span><span class="p">[</span><span class="s1">&#39;store_info&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">intent_classifier</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model_settings</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;classifier_type&#39;</span><span class="p">:</span> <span class="s1">&#39;logreg&#39;</span><span class="p">},</span>
        <span class="n">features</span><span class="o">=</span><span class="n">feature_dict</span><span class="p">,</span>
        <span class="n">param_selection</span><span class="o">=</span><span class="n">hyperparam_settings</span><span class="p">)</span>
</pre></div>
</div>
<p>We have now successfully trained an intent classifier for the <code class="docutils literal notranslate"><span class="pre">store_info</span></code> domain. If our app had more domains, we would follow the same procedure for those other domains. We can test the trained intent model on a new query&nbsp;by calling its <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_proba()</span></code> methods.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;Where is my closest Kwik-E-Mart?&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&#39;find_nearest_store&#39;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="s1">&#39;Where is my closest Kwik-E-Mart?&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[</span>
<span class="go">    (&#39;find_nearest_store&#39;, 0.999995),</span>
<span class="go">    (&#39;get_store_hours&#39;, 0.000005),</span>
<span class="go">    (&#39;greet&#39;, 0.000000),</span>
<span class="go">    (&#39;exit&#39;, 0.000000),</span>
<span class="go">    (&#39;help&#39;, 0.000000)</span>
<span class="go">]</span>
</pre></div>
</div>
<p>Once we have experimented with different settings and have an optimized intent model that we are happy with, we persist the trained model to a local file using the <code class="xref py py-meth docutils literal notranslate"><span class="pre">dump()</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">my_app_dump</span> <span class="o">=</span> <span class="s1">&#39;models/experimentation/intent_model_logreg.pkl&#39;</span>
<span class="n">clf</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">my_app_dump</span><span class="p">)</span>
</pre></div>
</div>
<p>See the <a class="reference internal" href="../userguide/intent_classifier.html"><span class="doc">User Guide</span></a> for a comprehensive list of the different model, feature extraction and hyperparameter settings for training the domain and intent models. The <a class="reference internal" href="../userguide/intent_classifier.html"><span class="doc">User Guide</span></a> also describes how to evaluate trained models using labeled test data.</p>
</div>
<div class="section" id="entity-recognition">
<span id="id3"></span><h2>Entity Recognition<a class="headerlink" href="#entity-recognition" title="Permalink to this headline">¶</a></h2>
<p>Entity recognizers (also called entity models) are <a class="reference external" href="https://en.wikipedia.org/wiki/Sequence_labeling">sequence labeling</a> models that are trained per intent using all the annotated queries in a particular intent folder in the <code class="docutils literal notranslate"><span class="pre">domains</span></code> directory. The entity recognizer detects the entities within a query, and labels them as one of the pre-defined entity types.</p>
<p>From the model hierarchy we defined for our Kwik-E-Mart app in <a class="reference internal" href="03_define_the_hierarchy.html#model-hierarchy"><span class="std std-ref">Step 3</span></a>, we can see that the <code class="docutils literal notranslate"><span class="pre">get_store_hours</span></code> intent depends on two types of entities. Of these, <code class="docutils literal notranslate"><span class="pre">sys_time</span></code> is a system entity that MindMeld recognizes automatically. The <code class="docutils literal notranslate"><span class="pre">store_name</span></code> entity, on the other hand, requires custom training data and a trained entity model. Let's look at how to use the <code class="xref py py-class docutils literal notranslate"><span class="pre">NaturalLanguageProcessor</span></code> class to train entity recognizers for detecting custom entities in user queries.</p>
<p>In this example we use a <a class="reference external" href="https://en.wikipedia.org/wiki/Maximum-entropy_Markov_model">Maximum Entropy Markov Model</a>, which is a good choice for sequence labeling tasks like entity recognition. The features we use include a <em>gazetteer</em> , which is a comprehensive list of popular entity names. <a class="reference external" href="https://gate.ac.uk/sale/tao/splitch13.html#x18-32600013.1">Gazetteers</a> are among the most powerful and commonly used sources of information in entity recognition models. Our example gazetteer for the <code class="docutils literal notranslate"><span class="pre">store_name</span></code> entity type is a list of all the Kwik-E-Mart store names in our catalog, stored in a text file called <code class="docutils literal notranslate"><span class="pre">gazetteer.txt</span></code> and located in the appropriate subdirectory of the <code class="docutils literal notranslate"><span class="pre">entities</span></code> folder. MindMeld automatically utilizes any gazetteer named <code class="docutils literal notranslate"><span class="pre">gazetteer.txt</span></code> that is located within an entity folder. The example gazetteer file looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>3rd Street
Central Plaza
East Oak Street
Elm Street
Evergreen Terrace
Main Street
Main and Market
Market Square
Shelbyville
Spalding Way
Springfield Mall
...
</pre></div>
</div>
<p>If we had&nbsp;more entity types, we would have gazetteer lists for them, too.</p>
<p>When words in a query fully or partly match a gazetteer entry, that can be used to derive features. This makes gazetteers particularly helpful for detecting entities which might otherwise seem to be a sequence of common nouns, such as <cite>main street</cite>, <cite>main and market</cite>, and so on. Apart from using gazetteer-based features, we'll use the bag of n-grams surrounding the token as additional features. Finally, we'll continue using 10-fold cross validation as before.</p>
<p>Below is the code to instantiate a <code class="xref py py-class docutils literal notranslate"><span class="pre">NaturalLanguageProcessor</span></code> object, define the features, and the hyperparameter selection settings.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;in-gaz-span-seq&#39;</span><span class="p">:</span> <span class="p">{},</span>
  <span class="s1">&#39;bag-of-words-seq&#39;</span><span class="p">:{</span>
      <span class="s1">&#39;ngram_lengths_to_start_positions&#39;</span><span class="p">:</span> <span class="p">{</span>
          <span class="mi">1</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
          <span class="mi">2</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
      <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="n">search_grid</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span>
  <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">hyperparam_settings</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;k-fold&#39;</span><span class="p">,</span>
  <span class="s1">&#39;k&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
  <span class="s1">&#39;grid&#39;</span><span class="p">:</span> <span class="n">search_grid</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Next, we get the entity recognizer for the desired intent and invoke its <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method. We also serialize the trained model to disk for future use.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">recognizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">domains</span><span class="p">[</span><span class="s1">&#39;store_info&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">intents</span><span class="p">[</span><span class="s1">&#39;get_store_hours&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">entity_recognizer</span>
<span class="n">recognizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model_settings</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;classifier_type&#39;</span><span class="p">:</span> <span class="s1">&#39;memm&#39;</span><span class="p">},</span>
               <span class="n">features</span><span class="o">=</span><span class="n">feature_dict</span><span class="p">,</span>
               <span class="n">param_selection</span><span class="o">=</span><span class="n">hyperparam_settings</span><span class="p">)</span>
<span class="n">recognizer</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="s1">&#39;models/experimentation/entity_model_memm.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We have now trained and saved the entity recognizer for the <code class="docutils literal notranslate"><span class="pre">get_store_hours</span></code> intent. If more entity recognizers were required, we would have repeated the same procedure for each entity in each intent. We test the trained entity recognizer using its <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">recognizer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;When does the store on Elm Street close?&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp gp-VirtualEnv">(&lt;QueryEntity &#39;Elm Street&#39; (&#39;store_name&#39;)</span> <span class="go">char: [23-32], tok: [5-6]&gt;,)</span>
</pre></div>
</div>
<p>See the <a class="reference internal" href="../userguide/entity_recognizer.html"><span class="doc">User Guide</span></a> for more about entity recognizer training and evaluation options.</p>
</div>
<div class="section" id="role-classification">
<span id="id4"></span><h2>Role Classification<a class="headerlink" href="#role-classification" title="Permalink to this headline">¶</a></h2>
<p>Role classifiers (also called role models) are trained per entity using all the annotated queries in a particular intent folder. Roles offer a way to assign an additional distinguishing label to entities of the same type. Our simple Kwik-E-Mart application does not need a role classification layer. However, consider a possible extension to our app, where users can search for stores that open and close at specific times. As we saw in the example in <a class="reference internal" href="06_generate_representative_training_data.html#roles-example"><span class="std std-ref">Step 6</span></a>, this would require us to differentiate between the two <code class="docutils literal notranslate"><span class="pre">sys_time</span></code> entities by recognizing one as an <code class="docutils literal notranslate"><span class="pre">open_time</span></code> and the other as a <code class="docutils literal notranslate"><span class="pre">close_time</span></code>. This can be accomplished by training an entity-specific role classifier that assigns the correct role label for each such <code class="docutils literal notranslate"><span class="pre">sys_time</span></code> entity detected by the Entity Recognizer.</p>
<p>Let's walk through the process of using MindMeld to train a role classifier for the <code class="docutils literal notranslate"><span class="pre">sys_time</span></code> entity type. The workflow is just like the previous classifiers: instantiate a <code class="xref py py-class docutils literal notranslate"><span class="pre">NaturalLanguageProcessor</span></code> object; access the classifier of interest (in this case, the <code class="xref py py-attr docutils literal notranslate"><span class="pre">role_classifier</span></code> for the <code class="docutils literal notranslate"><span class="pre">sys_time</span></code> entity); define the machine learning settings; and, call the <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code> method of the classifier. For this example, we will just use MindMeld's default configuration (Logistic Regression) to train a baseline role classifier without specifying any additional training settings. For the sake of code readability, we retrieve the classifier of interest in two steps: first get the object representing the current intent, then fetch the <code class="xref py py-attr docutils literal notranslate"><span class="pre">role_classifier</span></code> object of the appropriate entity under that intent.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The Kwik-E-Mart blueprint distributed with MindMeld does not use role classification. The code
snippet below shows a possible extension to the app where the <code class="docutils literal notranslate"><span class="pre">sys_time</span></code> entity is further
classified into two different roles.</p>
<p class="last">For an example you can run readily, see the <a class="reference internal" href="#ha-role-example"><span class="std std-ref">Home Assistant example</span></a>
further below.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">get_hours_intent</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">domains</span><span class="p">[</span><span class="s1">&#39;store_info&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">intents</span><span class="p">[</span><span class="s1">&#39;get_store_hours&#39;</span><span class="p">]</span>
<span class="c1"># MindMeld doesn&#39;t know about entities until the training queries have been loaded.</span>
<span class="c1"># Load queries for the relevant intent by calling build().</span>
<span class="n">get_hours_intent</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="c1"># Get the role classifier for the &#39;sys_time&#39; entity</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">get_hours_intent</span><span class="o">.</span><span class="n">entities</span><span class="p">[</span><span class="s1">&#39;sys_time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">role_classifier</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<p>Once the classifier is trained, we test it on a new query using the familiar <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code> method. The <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code> method of the role classifier requires both the full input query and the set of entities predicted by the entity recognizer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;Show me stores open between 8 AM and 6 PM.&#39;</span>
<span class="n">recognizer</span> <span class="o">=</span> <span class="n">get_hours_intent</span><span class="o">.</span><span class="n">entity_recognizer</span>
<span class="n">predicted_entities</span> <span class="o">=</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">predicted_entities</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&#39;open_time&#39;</span>
</pre></div>
</div>
<p id="ha-role-example">Here is a different example of role classification from the <a class="reference internal" href="../blueprints/home_assistant.html"><span class="doc">Home Assistant</span></a>
blueprint. The home assistant app leverages roles to correctly implement the functionality of
changing alarms, e.g. &quot;Change my 6 AM alarm to 7 AM&quot;.</p>
<p>First, we train the role classifier.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="n">app_path</span><span class="o">=</span><span class="s1">&#39;home_assistant&#39;</span><span class="p">)</span>
<span class="n">change_alarm_intent</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">domains</span><span class="p">[</span><span class="s1">&#39;times_and_dates&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">intents</span><span class="p">[</span><span class="s1">&#39;change_alarm&#39;</span><span class="p">]</span>
<span class="n">change_alarm_intent</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">change_alarm_intent</span><span class="o">.</span><span class="n">entities</span><span class="p">[</span><span class="s1">&#39;sys_time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">role_classifier</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<p>We can then test the classifier on a new query.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;Change my 6 AM alarm to 7 AM&#39;</span>
<span class="n">recognizer</span> <span class="o">=</span> <span class="n">change_alarm_intent</span><span class="o">.</span><span class="n">entity_recognizer</span>
<span class="n">predicted_entities</span> <span class="o">=</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">predicted_entities</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&#39;old_time&#39;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">predicted_entities</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">&#39;new_time&#39;</span>
</pre></div>
</div>
<p>We can further optimize our baseline role classifier using the training and evaluation options detailed in the <a class="reference internal" href="../userguide/role_classifier.html"><span class="doc">User Guide</span></a>.</p>
</div>
<div class="section" id="entity-resolution">
<span id="id5"></span><h2>Entity Resolution<a class="headerlink" href="#entity-resolution" title="Permalink to this headline">¶</a></h2>
<p>The entity resolver component of MindMeld maps each identified entity to a canonical value. For example, if your application is used for browsing TV shows, you may want to map both entity strings <cite>funny</cite> and <cite>hilarious</cite> to a pre-defined genre code like <cite>Comedy</cite>. Similarly, in a music app, you may want to resolve both <cite>Elvis</cite> and <cite>The King</cite> to the artist <cite>Elvis Presley (ID=20192)</cite>, while making sure not to get confused by <cite>Elvis Costello (ID=139028)</cite>. Entity resolution can be straightforward for some classes of entities. For others, it can be complex enough to constitute the dominant factor limiting the overall accuracy of your application.</p>
<p>MindMeld provides advanced capabilities for building a state-of-the-art entity resolver. As discussed in <a class="reference internal" href="06_generate_representative_training_data.html"><span class="doc">Step 6</span></a>, each entity type can be associated with an optional entity mapping file. This file specifies, for each canonical concept, the alternate names or synonyms with which a user may refer to this concept. In the absence of an entity mapping file, the entity resolver cannot resolve the entity. Instead, it logs a warning and skips adding a <code class="xref py py-attr docutils literal notranslate"><span class="pre">value</span></code> attribute to the entity. For example, the following code illustrates the output of the natural language processor when an entity mapping data file is absent for the <code class="docutils literal notranslate"><span class="pre">store_name</span></code> entity:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="s2">&quot;When does the one on elm open?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Failed to resolve entity &#39;elm&#39; for type &#39;store_name&#39;</span>
<span class="go">{</span>
<span class="go">  &#39;domain&#39;: &#39;store_info&#39;,</span>
<span class="go">  &#39;entities&#39;: [</span>
<span class="go">    {</span>
<span class="go">      &#39;role&#39;: None,</span>
<span class="go">      &#39;span&#39;: {&#39;end&#39;: 23, &#39;start&#39;: 21},</span>
<span class="go">      &#39;text&#39;: &#39;elm&#39;,</span>
<span class="go">      &#39;type&#39;: &#39;store_name&#39;</span>
<span class="go">     }</span>
<span class="go">  ],</span>
<span class="go">  &#39;intent&#39;: &#39;get_store_hours&#39;,</span>
<span class="go">  &#39;text&#39;: &#39;When does the one on elm open?&#39;</span>
<span class="go">}</span>
</pre></div>
</div>
<p>If an entity mapping file is specified, as illustrated in <a class="reference internal" href="06_generate_representative_training_data.html"><span class="doc">Step 6</span></a>, the entity resolver resolves the entity to a defined ID and canonical name. It assigns these to the <code class="xref py py-attr docutils literal notranslate"><span class="pre">value</span></code> attribute of the entity, in the form of an object. Then the output of the natural language processor could resemble the following.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="s2">&quot;When does the one on elm open?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">  &#39;domain&#39;: &#39;store_info&#39;,</span>
<span class="go">  &#39;entities&#39;: [</span>
<span class="go">    {</span>
<span class="go">      &#39;role&#39;: None,</span>
<span class="go">      &#39;span&#39;: {&#39;end&#39;: 23, &#39;start&#39;: 21},</span>
<span class="go">      &#39;text&#39;: &#39;elm&#39;,</span>
<span class="go">      &#39;type&#39;: &#39;store_name&#39;,</span>
<span class="go">      &#39;value&#39;: [{&#39;cname&#39;: &#39;23 Elm Street&#39;, &#39;id&#39;: &#39;1&#39;}],</span>
<span class="go">     }</span>
<span class="go">  ],</span>
<span class="go">  &#39;intent&#39;: &#39;get_store_hours&#39;,</span>
<span class="go">  &#39;text&#39;: &#39;When does the one on elm open?&#39;</span>
<span class="go">}</span>
</pre></div>
</div>
<p>As with the other NLP components in MindMeld, you can access the individual resolvers for each entity type.</p>
<p>The code below illustrates how to train and evaluate the entity resolver model for the <code class="docutils literal notranslate"><span class="pre">store_name</span></code> entity.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mindmeld.components.nlp</span> <span class="kn">import</span> <span class="n">NaturalLanguageProcessor</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">NaturalLanguageProcessor</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="c1"># MindMeld doesn&#39;t know about entities until the training queries have been loaded.</span>
<span class="c1"># Load queries for the relevant intent by calling build().</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">domains</span><span class="p">[</span><span class="s1">&#39;store_info&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">intents</span><span class="p">[</span><span class="s1">&#39;get_store_hours&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="c1"># Get the entity resolver for the entity type of interest.</span>
<span class="n">resolver</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">domains</span><span class="p">[</span><span class="s1">&#39;store_info&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">intents</span><span class="p">[</span><span class="s1">&#39;get_store_hours&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">entities</span><span class="p">[</span><span class="s1">&#39;store_name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">entity_resolver</span>

<span class="c1"># Train the resolver model using the mapping file, if available.</span>
<span class="n">resolver</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Run the model on a detected entity</span>
<span class="n">recognizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">domains</span><span class="p">[</span><span class="s1">&#39;store_info&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">intents</span><span class="p">[</span><span class="s1">&#39;get_store_hours&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">entity_recognizer</span>
<span class="n">entities</span> <span class="o">=</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;When does the store on Elm Street close?&#39;</span><span class="p">)</span>
<span class="n">resolver</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">entities</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">[{&#39;cname&#39;: &#39;23 Elm Street&#39;, &#39;score&#39;: 40.69433, &#39;top_synonym&#39;: &#39;Elm Street&#39;, &#39;id&#39;: &#39;1&#39;}, ...]</span>
</pre></div>
</div>
<p>See the <a class="reference internal" href="../userguide/entity_resolver.html"><span class="doc">User Guide</span></a> for more about how to evaluate and optimize entity resolution models.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="08_configure_the_language_parser.html" class="btn btn-neutral float-right" title="Step 8: Configure the Language Parser" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="06_generate_representative_training_data.html" class="btn btn-neutral float-left" title="Step 6: Generate Representative Training Data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Cisco Systems

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>